{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mri_dataset import MRIDataset\n",
    "from pytorch_resnet import PytorchResNet3D\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "def wl_to_lh(window, level):\n",
    "    low = level - window/2\n",
    "    high = level + window/2\n",
    "    return low,high\n",
    "\n",
    "def display_image(img, phys_size, x=None, y=None, z=None, window=None, level=None, existing_ax=None):\n",
    "    width, height, depth = phys_size\n",
    "    \n",
    "    size = np.flip(img.shape)\n",
    "    spacing = phys_size / size\n",
    "\n",
    "    if x is None:\n",
    "        x = np.floor(size[0]/2).astype(int)\n",
    "    if y is None:\n",
    "        y = np.floor(size[1]/2).astype(int)\n",
    "    if z is None:\n",
    "        z = np.floor(size[2]/2).astype(int)\n",
    "\n",
    "    if window is None:\n",
    "        window = np.max(img) - np.min(img)\n",
    "\n",
    "    if level is None:\n",
    "        level = window / 2 + np.min(img)\n",
    "\n",
    "    low,high = wl_to_lh(window,level)\n",
    "\n",
    "    if existing_ax is None:\n",
    "        # Display the orthogonal slices\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(14, 8))\n",
    "    else:\n",
    "        axes = existing_ax\n",
    "\n",
    "    axes[0].imshow(img[z,:,:], cmap='gray', clim=(low, high), extent=(0, width, height, 0))\n",
    "    axes[1].imshow(img[:,y,:], origin='lower', cmap='gray', clim=(low, high), extent=(0, width,  0, depth))\n",
    "    axes[2].imshow(img[:,:,x], origin='lower', cmap='gray', clim=(low, high), extent=(0, height, 0, depth))\n",
    "\n",
    "    # Additionally display crosshairs\n",
    "    axes[0].axhline(y * spacing[1], lw=1)\n",
    "    axes[0].axvline(x * spacing[0], lw=1)\n",
    "\n",
    "    axes[1].axhline(z * spacing[2], lw=1)\n",
    "    axes[1].axvline(x * spacing[0], lw=1)\n",
    "\n",
    "    axes[2].axhline(z * spacing[2], lw=1)\n",
    "    axes[2].axvline(y * spacing[1], lw=1)\n",
    "\n",
    "    if existing_ax is None:\n",
    "        plt.show()\n",
    "\n",
    "def display_patient_torch(d_set, i, box_size):\n",
    "    sample = d_set[i][0]\n",
    "    display_image(sample[0].numpy(), box_size)\n",
    "    display_image(sample[1].numpy(), box_size)\n",
    "    display_image(sample[2].numpy(), box_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "localised_box_size = np.array([80, 80, 112])\n",
    "generalised_box_size = np.array([0.289, 0.307483, 0.4804149]) * 200\n",
    "\n",
    "base = '/vol/bitbucket/mb4617'\n",
    "data_path = f'{base}/MRI_Crohns/numpy_datasets'\n",
    "models_path = f'{base}/CrohnsDisease/trained_models'\n",
    "suffix = 'all_data'\n",
    "input_size = [87, 87, 87]\n",
    "\n",
    "all_modalities = True\n",
    "localisation = True\n",
    "attention = True\n",
    "fold = 0\n",
    "\n",
    "input_features = [1, 1, 1] if all_modalities else [1, 0, 0]\n",
    "folder = 'ti_imb' if localisation else 'ti_imb_generic'\n",
    "\n",
    "dataset_path = f'{data_path}/{folder}/{suffix}_test_fold{fold}.npz'\n",
    "train_dataset_path = f'{data_path}/{folder}/{suffix}_train_fold{fold}.npz'\n",
    "\n",
    "curr_model_path = f'{models_path}/original_dataset_mode{int(all_modalities)}loc{int(localisation)}att{int(attention)}/fold{fold}'\n",
    "\n",
    "dataset = MRIDataset(train_dataset_path, False, input_size, input_features)\n",
    "\n",
    "# model = PytorchResNet3D(input_size, attention, 0.5, sum(input_features))\n",
    "\n",
    "# model.load_state_dict(torch.load(f'{models_path}/best_model/fold{fold}'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model.to(device=device)\n",
    "print('Device: ', device)\n",
    "\n",
    "loader = DataLoader(dataset, len(dataset), False)\n",
    "\n",
    "correct = 0\n",
    "for x, y in loader:\n",
    "    \n",
    "    x = x.to(device=device)\n",
    "    binary_y = torch.where(y == 0, 0, 1).to(device=device)\n",
    "    print('labels: ', binary_y)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(x)\n",
    "    \n",
    "    preds = out.argmax(dim=1).float()\n",
    "    print('predictions: ', preds)\n",
    "    print('accuracy: ', (preds == binary_y).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = preds == binary_y\n",
    "\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    if correct_predictions[i]:\n",
    "        continue\n",
    "    \n",
    "    print('Index: ', i)\n",
    "    print('Label: ', binary_y[i])\n",
    "    print('Pred:  ', preds[i])\n",
    "    display_patient_torch(dataset, i, localised_box_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "improve = torch.Tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
    "           0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
    "           1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
    "           0., 1., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
    "           0., 0., 0.])\n",
    "\n",
    "print(confusion_matrix(binary_y.cpu(), preds.cpu()))\n",
    "print(f1_score(binary_y.cpu(), preds.cpu(), zero_division=0, average='weighted'))\n",
    "print(f1_score(binary_y.cpu(), improve, zero_division=0, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mri_dataset import _random_rotate, _random_crop_gen\n",
    "import torchvision.transforms as T\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "def _random_rotate_test(x):\n",
    "    angle = np.random.normal(loc=0, scale=4)\n",
    "    rotated_np = rotate(x, angle, axes=(2, 3), reshape=False, order=1, mode='nearest')\n",
    "    return torch.from_numpy(rotated_np)\n",
    "\n",
    "standard_dataset = MRIDataset(dataset_path, True, input_size, input_features, fast_rotate=False)\n",
    "dataset_rot = MRIDataset(dataset_path, False, input_size, input_features, transforms=T.Lambda(_random_rotate_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import cProfile\n",
    "\n",
    "# Full augmentation ~ 37\n",
    "\n",
    "## ~2s for nearest padding instead of constant\n",
    "\n",
    "## Singel worker\n",
    "## 5 - 35s\n",
    "## 3 - 18s\n",
    "## 2 - 15s\n",
    "## 1 - 8.269\n",
    "\n",
    "with cProfile.Profile() as pr:\n",
    "    \n",
    "    rotated_images = [standard_dataset[0][0][0] for _ in range(48)]\n",
    "\n",
    "pr.print_stats()\n",
    "# for i in range(1, 5):\n",
    "#     display_image(rotated_images[i].numpy(), localised_box_size)\n",
    "#     print(np.allclose(rotated_images[0].numpy(), rotated_images[i].numpy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Multimodal tests, different number of workers\n",
    "\n",
    "## not given - 34.026\n",
    "## 1 - 36.214s\n",
    "## 2 - 36.395\n",
    "## 4 - 36.405\n",
    "## 6 - 37.477\n",
    "## 8 - 37.023\n",
    "\n",
    "## full model tests, 4 workers\n",
    "# norm 36.66/38.22\n",
    "# fast  7.48/ 9.03\n",
    "\n",
    "worker_loader = DataLoader(standard_dataset, len(standard_dataset), False, num_workers=4)\n",
    "\n",
    "start_t = time()\n",
    "# with cProfile.Profile() as pr:\n",
    "    \n",
    "for x, y in worker_loader:\n",
    "    x = x.to(device=device)\n",
    "    binary_y = torch.where(y == 0, 0, 1).to(device=device)\n",
    "\n",
    "    print(time() - start_t)\n",
    "    with torch.no_grad():\n",
    "        out = model(x)\n",
    "    preds = out.argmax(dim=1).float()\n",
    "\n",
    "    print((preds == binary_y).float().mean())\n",
    "\n",
    "# pr.print_stats()\n",
    "print(time() - start_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cProfile.Profile() as pr:\n",
    "    \n",
    "    rotated_images = [standard_dataset[0][0][0] for _ in range(48)]\n",
    "\n",
    "pr.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = T.InterpolationMode.BILINEAR\n",
    "\n",
    "dataset_rot_2 = MRIDataset(dataset_path, False, input_size, input_features, transforms=T.RandomRotation(8, interpolation=interp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with cProfile.Profile() as pr:\n",
    "    \n",
    "    rotated_images = [dataset_rot_2[0][0][0] for _ in range(48)]\n",
    "    \n",
    "pr.print_stats()\n",
    "# for i in range(1, 5):\n",
    "#     display_image(rotated_images[i].numpy(), localised_box_size)\n",
    "#     print(np.allclose(rotated_images[0].numpy(), rotated_images[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0.9s for batch of 48\n",
    "class MyRotationTransform:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "\n",
    "    def __init__(self, std):\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, x):\n",
    "        angle = np.random.normal(loc=0, scale=self.std)\n",
    "        return self._rotate_by(x, angle)\n",
    "    \n",
    "    def _rotate_by(self, x, angle):\n",
    "        \n",
    "        _, _, height, width = x.shape\n",
    "        corner_angle = np.arctan(height / width)\n",
    "        rad_angle = np.radians(np.abs(angle))\n",
    "        \n",
    "        distance_to_top_corner = np.hypot(height, width) * 0.5 * np.sin(corner_angle + rad_angle)\n",
    "        pad_amount = int(np.ceil(distance_to_top_corner - height // 2))\n",
    "        \n",
    "        x = T.functional.pad(x, pad_amount, padding_mode='edge')\n",
    "        \n",
    "        x = T.functional.rotate(x, angle, interpolation=interp)\n",
    "        return T.functional.center_crop(x, (height, width))\n",
    "        \n",
    "    \n",
    "dataset_rot_3 = MRIDataset(dataset_path, False, input_size, input_features, transforms=MyRotationTransform(4.0))\n",
    "\n",
    "\n",
    "with cProfile.Profile() as pr:\n",
    "    \n",
    "    rotated_images = [dataset_rot_3[0][0][0] for _ in range(48)]\n",
    "    \n",
    "pr.print_stats()\n",
    "\n",
    "\n",
    "for i in range(0, 5):\n",
    "    display_image(rotated_images[i].numpy(), localised_box_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_rotate_test2(x, angle):\n",
    "    rotated_np = rotate(x, angle, axes=(2, 3), reshape=False, order=5, mode='nearest')\n",
    "    return torch.from_numpy(rotated_np)\n",
    "\n",
    "test_sample = dataset.data[0][0]\n",
    "print(test_sample.shape)\n",
    "\n",
    "for ang in range(-8, 9, 2):\n",
    "    print(ang)\n",
    "    display_image(_random_rotate_test2(test_sample, ang)[0].numpy(), generalised_box_size)\n",
    "    display_image(MyRotationTransform(1)._rotate_by(test_sample, ang)[0].numpy(), generalised_box_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RandomModalityShift:\n",
    "    def __init__(self, out_shape):\n",
    "        ## Must be even number less than input\n",
    "        self.out_shape = out_shape\n",
    "        \n",
    "    def _shift_single_channel(self, channel):\n",
    "        depth, height, width = self.out_shape\n",
    "        d, h, w = channel.shape\n",
    "        \n",
    "        z_diff = d - depth\n",
    "        y_diff = h - height\n",
    "        x_diff = w - width\n",
    "        \n",
    "        k = torch.randint(0, z_diff + 1, size=(1, )).item()\n",
    "        j = torch.randint(0, y_diff + 1, size=(1, )).item()\n",
    "        i = torch.randint(0, x_diff + 1, size=(1, )).item()\n",
    "        \n",
    "        return channel[k: k + depth, j: j + height, i: i + width]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        c, d, h, w = x.shape\n",
    "        depth, height, width = self.out_shape\n",
    "        \n",
    "        # Do nothing if only single modality\n",
    "        if c == 1:\n",
    "            return x\n",
    "        \n",
    "        axial = x[0]\n",
    "        \n",
    "        z_d = (d - depth) // 2\n",
    "        y_d = (h - height) // 2\n",
    "        x_d = (w - width) // 2\n",
    "        \n",
    "        axial_cropped = axial[z_d: z_d + depth, y_d: y_d + height, x_d: x_d + width]\n",
    "        \n",
    "        return torch.stack([axial_cropped, *[self._shift_single_channel(ch) for ch in x[1:]]])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_patient_torch(dataset.data, 14, localised_box_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dims = [99, 99, 99]\n",
    "out_dims = [87, 87, 87]\n",
    "\n",
    "test_shape = np.ceil((np.array(in_dims) + np.array(out_dims)) / 2).astype(int)\n",
    "print(test_shape)\n",
    "test_shift = RandomModalityShift(test_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(dataset.data[14][0][2].numpy(), localised_box_size)\n",
    "\n",
    "for _ in range(3):\n",
    "    display_image(test_shift(dataset.data[14][0])[2].numpy(), localised_box_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
